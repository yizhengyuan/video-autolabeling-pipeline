#!/usr/bin/env python3
"""
YOLO11 æœ¬åœ°è‡ªåŠ¨æ ‡æ³¨è„šæœ¬
å®Œå…¨å…è´¹ï¼Œæ”¯æŒç¦»çº¿ä½¿ç”¨ï¼Œé€Ÿåº¦å¿«
"""

import cv2
import json
import os
from pathlib import Path
from typing import List, Dict, Tuple
import argparse
import time

try:
    from ultralytics import YOLO
except ImportError:
    print("é”™è¯¯: æœªå®‰è£… ultralytics åº“")
    print("è¯·è¿è¡Œ: pip install ultralytics")
    exit(1)


# COCOæ•°æ®é›†ç±»åˆ«æ˜ å°„åˆ°ä¸­æ–‡ï¼ˆYOLOé¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨COCOæ•°æ®é›†ï¼‰
COCO_TO_CHINESE = {
    "person": "è¡Œäºº",
    "bicycle": "è‡ªè¡Œè½¦",
    "car": "æ±½è½¦",
    "motorcycle": "æ‘©æ‰˜è½¦",
    "bus": "å…¬äº¤è½¦",
    "truck": "å¡è½¦",
    "traffic light": "äº¤é€šä¿¡å·ç¯",
    "stop sign": "åœæ­¢æ ‡å¿—",
    # å®Œæ•´çš„COCO 80ç±»
    "airplane": "é£æœº",
    "train": "ç«è½¦",
    "boat": "èˆ¹",
    "bird": "é¸Ÿ",
    "cat": "çŒ«",
    "dog": "ç‹—",
    "horse": "é©¬",
    "sheep": "ç¾Š",
    "cow": "ç‰›",
    "elephant": "å¤§è±¡",
    "bear": "ç†Š",
    "zebra": "æ–‘é©¬",
    "giraffe": "é•¿é¢ˆé¹¿",
    "backpack": "èƒŒåŒ…",
    "umbrella": "é›¨ä¼",
    "handbag": "æ‰‹æåŒ…",
    "tie": "é¢†å¸¦",
    "suitcase": "è¡Œæç®±",
    "frisbee": "é£ç›˜",
    "skis": "æ»‘é›ªæ¿",
    "snowboard": "æ»‘é›ªæ¿",
    "sports ball": "è¿åŠ¨çƒ",
    "kite": "é£ç­",
    "baseball bat": "æ£’çƒæ£’",
    "baseball glove": "æ£’çƒæ‰‹å¥—",
    "skateboard": "æ»‘æ¿",
    "surfboard": "å†²æµªæ¿",
    "tennis racket": "ç½‘çƒæ‹",
    "bottle": "ç“¶å­",
    "wine glass": "é…’æ¯",
    "cup": "æ¯å­",
    "fork": "å‰å­",
    "knife": "åˆ€",
    "spoon": "å‹ºå­",
    "bowl": "ç¢—",
    "banana": "é¦™è•‰",
    "apple": "è‹¹æœ",
    "sandwich": "ä¸‰æ˜æ²»",
    "orange": "æ©™å­",
    "broccoli": "è¥¿å…°èŠ±",
    "carrot": "èƒ¡èåœ",
    "hot dog": "çƒ­ç‹—",
    "pizza": "æŠ«è¨",
    "donut": "ç”œç”œåœˆ",
    "cake": "è›‹ç³•",
    "chair": "æ¤…å­",
    "couch": "æ²™å‘",
    "potted plant": "ç›†æ ½",
    "bed": "åºŠ",
    "dining table": "é¤æ¡Œ",
    "toilet": "é©¬æ¡¶",
    "tv": "ç”µè§†",
    "laptop": "ç¬”è®°æœ¬ç”µè„‘",
    "mouse": "é¼ æ ‡",
    "remote": "é¥æ§å™¨",
    "keyboard": "é”®ç›˜",
    "cell phone": "æ‰‹æœº",
    "microwave": "å¾®æ³¢ç‚‰",
    "oven": "çƒ¤ç®±",
    "toaster": "çƒ¤é¢åŒ…æœº",
    "sink": "æ°´æ§½",
    "refrigerator": "å†°ç®±",
    "book": "ä¹¦",
    "clock": "æ—¶é’Ÿ",
    "vase": "èŠ±ç“¶",
    "scissors": "å‰ªåˆ€",
    "teddy bear": "æ³°è¿ªç†Š",
    "hair drier": "å¹é£æœº",
    "toothbrush": "ç‰™åˆ·",
}

# äº¤é€šåœºæ™¯ç›¸å…³ç±»åˆ«ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
TRAFFIC_CATEGORIES = {
    "person", "bicycle", "car", "motorcycle", "bus", "truck",
    "traffic light", "stop sign"
}


class YOLOVideoLabeler:
    """YOLOè§†é¢‘è‡ªåŠ¨æ ‡æ³¨å™¨"""
    
    def __init__(self, model_name: str = "yolo11n.pt", confidence: float = 0.25):
        """
        Args:
            model_name: YOLOæ¨¡å‹åç§°
                - yolo11n.pt: æœ€å¿«ï¼Œå‡†ç¡®åº¦è¾ƒä½ï¼ˆæ¨èå¿«é€Ÿæµ‹è¯•ï¼‰
                - yolo11s.pt: å¹³è¡¡
                - yolo11m.pt: ä¸­ç­‰
                - yolo11l.pt: å¤§æ¨¡å‹
                - yolo11x.pt: æœ€å‡†ç¡®ï¼Œæœ€æ…¢
            confidence: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        """
        self.model_name = model_name
        self.confidence = confidence
        
        print(f"åŠ è½½YOLOæ¨¡å‹: {model_name}")
        print("é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        
        self.model = YOLO(model_name)
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        
    def detect_video(
        self, 
        video_path: str, 
        sample_rate: int = 30,
        traffic_only: bool = True
    ) -> Tuple[List[Dict], Dict]:
        """
        æ£€æµ‹è§†é¢‘ä¸­çš„ç›®æ ‡
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            sample_rate: é‡‡æ ·ç‡ï¼ˆæ¯Nå¸§æ£€æµ‹ä¸€æ¬¡ï¼‰
            traffic_only: æ˜¯å¦åªæ£€æµ‹äº¤é€šç›¸å…³ç›®æ ‡
            
        Returns:
            (æ£€æµ‹ç»“æœåˆ—è¡¨, è§†é¢‘ä¿¡æ¯)
        """
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        video_info = {
            "fps": fps,
            "total_frames": total_frames,
            "width": width,
            "height": height,
            "duration": total_frames / fps
        }
        
        print(f"\nè§†é¢‘ä¿¡æ¯:")
        print(f"  åˆ†è¾¨ç‡: {width}x{height}")
        print(f"  å¸§ç‡: {fps} fps")
        print(f"  æ€»å¸§æ•°: {total_frames}")
        print(f"  æ—¶é•¿: {video_info['duration']:.2f} ç§’")
        print(f"  é‡‡æ ·ç‡: æ¯ {sample_rate} å¸§")
        print()
        
        frame_detections = []
        frame_count = 0
        detected_count = 0
        
        start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # æŒ‰é‡‡æ ·ç‡æ£€æµ‹
            if frame_count % sample_rate == 0:
                # è¿è¡Œæ£€æµ‹
                results = self.model(
                    frame, 
                    conf=self.confidence,
                    verbose=False  # ä¸æ˜¾ç¤ºæ¯å¸§çš„è¯¦ç»†ä¿¡æ¯
                )
                
                # è§£æç»“æœ
                objects = []
                for result in results:
                    boxes = result.boxes
                    for box in boxes:
                        # è·å–ç±»åˆ«åç§°
                        cls_id = int(box.cls[0])
                        cls_name = result.names[cls_id]
                        
                        # è¿‡æ»¤éäº¤é€šç±»åˆ«
                        if traffic_only and cls_name not in TRAFFIC_CATEGORIES:
                            continue
                        
                        # è·å–è¾¹ç•Œæ¡†ï¼ˆxyxyæ ¼å¼ï¼‰
                        x1, y1, x2, y2 = box.xyxy[0].tolist()
                        
                        # è½¬æ¢ä¸ºç›¸å¯¹åæ ‡ï¼ˆ0-1èŒƒå›´ï¼‰
                        bbox = [
                            x1 / width,
                            y1 / height,
                            x2 / width,
                            y2 / height
                        ]
                        
                        # è·å–ç½®ä¿¡åº¦
                        conf = float(box.conf[0])
                        
                        # è½¬æ¢ä¸ºä¸­æ–‡ç±»åˆ«
                        category_cn = COCO_TO_CHINESE.get(cls_name, cls_name)
                        
                        objects.append({
                            "category": category_cn,
                            "category_en": cls_name,
                            "bbox": bbox,
                            "confidence": conf,
                            "frame": frame_count,
                            "time": frame_count / fps
                        })
                
                frame_detections.append({
                    "frame": frame_count,
                    "objects": objects
                })
                
                detected_count += 1
                if detected_count % 10 == 0:
                    elapsed = time.time() - start_time
                    fps_processing = detected_count / elapsed
                    print(f"å·²å¤„ç† {detected_count} å¸§ ({frame_count}/{total_frames}) "
                          f"- é€Ÿåº¦: {fps_processing:.1f} å¸§/ç§’")
            
            frame_count += 1
        
        cap.release()
        
        elapsed = time.time() - start_time
        print(f"\nâœ“ æ£€æµ‹å®Œæˆ!")
        print(f"  æ€»è€—æ—¶: {elapsed:.2f} ç§’")
        print(f"  å¤„ç†é€Ÿåº¦: {detected_count/elapsed:.1f} å¸§/ç§’")
        print(f"  æ£€æµ‹å¸§æ•°: {detected_count}")
        
        # ç»Ÿè®¡æ£€æµ‹åˆ°çš„ç›®æ ‡
        total_objects = sum(len(fd["objects"]) for fd in frame_detections)
        print(f"  æ£€æµ‹åˆ°ç›®æ ‡æ€»æ•°: {total_objects}")
        
        return frame_detections, video_info
    
    def convert_to_label_studio(
        self, 
        video_path: str,
        detections: List[Dict],
        video_info: Dict
    ) -> Dict:
        """è½¬æ¢ä¸ºLabel Studioæ ¼å¼"""
        
        results = []
        
        for frame_data in detections:
            for obj in frame_data["objects"]:
                bbox = obj["bbox"]
                
                # Label Studioä½¿ç”¨ x, y, width, height æ ¼å¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
                result = {
                    "value": {
                        "x": bbox[0] * 100,
                        "y": bbox[1] * 100,
                        "width": (bbox[2] - bbox[0]) * 100,
                        "height": (bbox[3] - bbox[1]) * 100,
                        "rotation": 0,
                        "rectanglelabels": [obj["category"]],
                        "frame": obj["frame"],
                        "time": obj["time"]
                    },
                    "from_name": "videoLabels",
                    "to_name": "video",
                    "type": "videorectangle",
                    "meta": {
                        "confidence": obj["confidence"]
                    }
                }
                results.append(result)
        
        return {
            "data": {
                "video": f"/data/local-files/?d={os.path.basename(video_path)}"
            },
            "predictions": [{
                "result": results,
                "score": 0.0,
                "model_version": self.model_name
            }]
        }


def main():
    parser = argparse.ArgumentParser(
        description="YOLO11 æœ¬åœ°è§†é¢‘è‡ªåŠ¨æ ‡æ³¨å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼ˆnanoï¼Œæœ€å¿«ï¼‰
  python yolo_auto_labeling.py video.mp4
  
  # ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆæ›´å‡†ç¡®ï¼‰
  python yolo_auto_labeling.py video.mp4 --model yolo11m.pt
  
  # è°ƒæ•´é‡‡æ ·ç‡å’Œç½®ä¿¡åº¦
  python yolo_auto_labeling.py video.mp4 --sample-rate 10 --confidence 0.4
  
  # æ£€æµ‹æ‰€æœ‰ç±»åˆ«ï¼ˆä¸åªæ˜¯äº¤é€šç›¸å…³ï¼‰
  python yolo_auto_labeling.py video.mp4 --all-categories
        """
    )
    
    parser.add_argument("video_path", help="è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--model", 
        default="yolo11n.pt",
        choices=["yolo11n.pt", "yolo11s.pt", "yolo11m.pt", "yolo11l.pt", "yolo11x.pt"],
        help="YOLOæ¨¡å‹å¤§å° (n=æœ€å¿«, x=æœ€å‡†ç¡®)"
    )
    parser.add_argument(
        "--confidence", 
        type=float, 
        default=0.25,
        help="ç½®ä¿¡åº¦é˜ˆå€¼ (0-1, é»˜è®¤0.25)"
    )
    parser.add_argument(
        "--sample-rate", 
        type=int, 
        default=30,
        help="é‡‡æ ·ç‡ï¼ˆæ¯Nå¸§æ£€æµ‹ä¸€æ¬¡ï¼Œé»˜è®¤30ï¼‰"
    )
    parser.add_argument(
        "--all-categories",
        action="store_true",
        help="æ£€æµ‹æ‰€æœ‰ç±»åˆ«ï¼ˆé»˜è®¤åªæ£€æµ‹äº¤é€šç›¸å…³ç±»åˆ«ï¼‰"
    )
    parser.add_argument(
        "--output", 
        default="yolo_labels.json",
        help="è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„"
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("YOLO11 æœ¬åœ°è§†é¢‘è‡ªåŠ¨æ ‡æ³¨å·¥å…·")
    print("=" * 60)
    print(f"è§†é¢‘æ–‡ä»¶: {args.video_path}")
    print(f"YOLOæ¨¡å‹: {args.model}")
    print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {args.confidence}")
    print(f"é‡‡æ ·ç‡: æ¯ {args.sample_rate} å¸§")
    print(f"ç±»åˆ«è¿‡æ»¤: {'å…³é—­ï¼ˆæ‰€æœ‰ç±»åˆ«ï¼‰' if args.all_categories else 'å¼€å¯ï¼ˆä»…äº¤é€šç›¸å…³ï¼‰'}")
    print("=" * 60)
    
    # åˆ›å»ºæ ‡æ³¨å™¨
    labeler = YOLOVideoLabeler(
        model_name=args.model,
        confidence=args.confidence
    )
    
    # æ£€æµ‹è§†é¢‘
    detections, video_info = labeler.detect_video(
        args.video_path,
        sample_rate=args.sample_rate,
        traffic_only=not args.all_categories
    )
    
    # è½¬æ¢ä¸ºLabel Studioæ ¼å¼
    print("\nè½¬æ¢ä¸ºLabel Studioæ ¼å¼...")
    label_studio_data = labeler.convert_to_label_studio(
        args.video_path,
        detections,
        video_info
    )
    
    # ä¿å­˜ç»“æœ
    with open(args.output, "w", encoding="utf-8") as f:
        json.dump([label_studio_data], f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ“ å®Œæˆï¼æ ‡æ³¨ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    print(f"\nğŸ“‹ å¯¼å…¥Label Studioçš„æ­¥éª¤ï¼š")
    print(f"1. åœ¨Label Studioé¡¹ç›®ä¸­ç‚¹å‡»å³ä¸Šè§’ 'Import'")
    print(f"2. ä¸Šä¼  {args.output} æ–‡ä»¶")
    print(f"3. é€‰æ‹© 'Treat as predictions' (ä½œä¸ºé¢„æ ‡æ³¨)")
    print(f"4. å¼€å§‹äººå·¥å®¡æ ¸å’Œä¿®æ­£ï¼")
    
    # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡
    print(f"\nğŸ“Š æ£€æµ‹ç»Ÿè®¡ï¼š")
    category_stats = {}
    for frame_data in detections:
        for obj in frame_data["objects"]:
            cat = obj["category"]
            category_stats[cat] = category_stats.get(cat, 0) + 1
    
    for cat, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  {cat}: {count} ä¸ª")


if __name__ == "__main__":
    main()
