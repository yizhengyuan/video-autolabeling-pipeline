#!/usr/bin/env python3
"""
å¯è§†åŒ–æ ‡æ³¨ç»“æœ - åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
"""

import cv2
import json
import sys

def visualize_annotations(video_path, json_path, output_path, frame_number=30):
    """
    ä»è§†é¢‘æå–ä¸€å¸§å¹¶ç»˜åˆ¶æ ‡æ³¨æ¡†
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        json_path: Label Studio JSONæ ‡æ³¨æ–‡ä»¶
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        frame_number: è¦å¯è§†åŒ–çš„å¸§å·
    """
    # è¯»å–è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    
    # è·³è½¬åˆ°æŒ‡å®šå¸§
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
    ret, frame = cap.read()
    
    if not ret:
        print(f"âŒ æ— æ³•è¯»å–å¸§ {frame_number}")
        return
    
    height, width = frame.shape[:2]
    cap.release()
    
    # è¯»å–æ ‡æ³¨
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = data[0]['predictions'][0]['result']
    
    # é¢œè‰²æ˜ å°„
    colors = {
        "è¡Œäºº": (255, 112, 67),      # æ©™è‰²
        "æ±½è½¦": (66, 165, 245),       # è“è‰²
        "æ‘©æ‰˜è½¦": (102, 187, 106),    # ç»¿è‰²
        "è‡ªè¡Œè½¦": (255, 193, 7),      # é»„è‰²
        "äº¤é€šæ ‡å¿—": (156, 39, 176),   # ç´«è‰²
        "äº¤é€šä¿¡å·ç¯": (38, 198, 218), # é’è‰²
        "æ–½å·¥åŒºåŸŸ": (255, 87, 34),    # æ·±æ©™è‰²
        "å…¶ä»–": (158, 158, 158)       # ç°è‰²
    }
    
    # ç­›é€‰è¯¥å¸§çš„æ ‡æ³¨
    frame_results = [r for r in results if r['value']['frame'] == frame_number]
    
    print(f"ğŸ“Š å¸§ {frame_number} æ£€æµ‹åˆ° {len(frame_results)} ä¸ªç›®æ ‡")
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†
    for i, result in enumerate(frame_results, 1):
        value = result['value']
        category = value['rectanglelabels'][0]
        
        # ä»ç™¾åˆ†æ¯”è½¬æ¢ä¸ºåƒç´ åæ ‡
        x = int(value['x'] * width / 100)
        y = int(value['y'] * height / 100)
        w = int(value['width'] * width / 100)
        h = int(value['height'] * height / 100)
        
        # è·å–é¢œè‰²
        color = colors.get(category, (255, 255, 255))
        
        # ç»˜åˆ¶çŸ©å½¢æ¡†ï¼ˆåŠ ç²—ï¼‰
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)
        
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        label = f"{category} #{i}"
        (label_w, label_h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
        cv2.rectangle(frame, (x, y - label_h - 15), (x + label_w + 10, y), color, -1)
        
        # ç»˜åˆ¶æ–‡å­—
        cv2.putText(frame, label, (x + 5, y - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        print(f"  {i}. {category} - ä½ç½®: ({x}, {y}), å¤§å°: ({w}x{h})")
    
    # æ·»åŠ æ ‡é¢˜
    title = f"Frame {frame_number} - {len(frame_results)} objects detected"
    cv2.putText(frame, title, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(output_path, frame)
    print(f"\nâœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
    print(f"   åˆ†è¾¨ç‡: {width}x{height}")


if __name__ == "__main__":
    video_path = "../data/D1_video_clips/D1_rand11-15_clip_000.mp4"
    json_path = "../labels/test_qwen_result.json"
    output_path = "../labels/visualization_frame30.jpg"
    
    print("ğŸ¨ åˆ›å»ºå¯è§†åŒ–ç»“æœ...")
    print(f"è§†é¢‘: {video_path}")
    print(f"æ ‡æ³¨: {json_path}")
    print()
    
    visualize_annotations(video_path, json_path, output_path, frame_number=30)
    
    # ä¹Ÿå¯è§†åŒ–å…¶ä»–å¸§
    print("\n" + "="*60)
    print("ğŸ¨ åˆ›å»ºç¬¬äºŒä¸ªå¯è§†åŒ–ï¼ˆå¸§180ï¼‰...")
    print()
    visualize_annotations(video_path, json_path, "../labels/visualization_frame180.jpg", frame_number=180)

